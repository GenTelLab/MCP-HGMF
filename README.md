# ğŸŒŸ HGMF: Hierarchical Gaussian Mixture Framework

A Scalable Probabilistic Pruning Paradigm for Tool Invocation Based on Model Context Protocol.

<div align="center">
  <img src="HGMF/img/img1.png" alt="HGMF Workflow" width="600"/>
  <p><strong>HGMF </strong></p>
  <p>
     <a href="https://arxiv.org/abs/2508.07602" target="_blank" style="text-decoration: none;">
      <span style="background-color: #1e90ff; color: white; padding: 5px 10px; border-radius: 5px; font-weight: bold;">
        ğŸ”— arXiv:2508.07602
      </span
    </a>
  </p>
</div>


---

## ğŸš€ Overview

HGMF (Hierarchical Gaussian Mixture Framework) is a cutting-edge framework designed to enable scalable and efficient tool invocation within the Model Context Protocol. By leveraging probabilistic pruning and hierarchical modeling, HGMF optimizes tool selection and enhances performance in complex AI-driven workflows. This repository provides all the necessary tools, scripts, and configurations to replicate our experiments and explore the framework's capabilities.

---

## ğŸ“‚ Project Structure

```plaintext
HGMF/
â”œâ”€â”€ main.py                  # ğŸš€ Main script for experiment execution
â”œâ”€â”€ matcher.py               # ğŸ” Code for similarity matching
â”œâ”€â”€ sampler.py               # ğŸ¯ Sampler for selecting target tools
â”œâ”€â”€ utils.py                 # ğŸ› ï¸ Utility functions, including grid search
â”œâ”€â”€ reformatter.py           # ğŸ“ JSON formatter for tool descriptions
â”œâ”€â”€ config.py                # âš™ï¸ Configuration file for experiment parameters
â”œâ”€â”€ data_embeddings.json     # ğŸ“Š Embeddings for tools and servers
â””â”€â”€ professional_embedding.json # ğŸ’¼ Professional description embeddings
```

---

## ğŸ› ï¸ Getting Started

### Prerequisites

- **Python**: Version 3.10.x
- **Conda**: For virtual environment management
- **Hardware**: Compatible with standard GPU setups

### Environment Setup

1. **Create and Activate a Virtual Environment**:
   ```bash
   conda create -n hgmf_env python=3.10 -y
   conda activate hgmf_env
   ```

2. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

### Model Download

1. Download the required Large Language Model (LLM) via **Ollama**:
   ```bash
   ollama pull <llm-name>
   ```

2. Launch the model server:
   ```bash
   ollama serve
   ```

### Dataset
Dataset Resource ï¼šThis dataset is derived from the official MCP repository, containing all filtered tools from the repo: it includes 308 servers and a total of 2,797 tools. For subsequent task adaptation , I have converted the tool data in this dataset into  embeddings .
The following datasets are included in the repository:
- `data_embeddings.json`: ğŸ—„ï¸ Origin Embeddings for tools and servers.
- `professional_embedding.json`: ğŸ“‹ Professional description embeddings.
---

## ğŸ§ª Running Experiments

1. **Execute the Main Program**:
   ```bash
   python main.py
   ```

2. **Results**:
   Experiment outputs will be saved in the `grid_search_results/` directory for easy access and analysis.

---

## âš™ï¸ Configuration

- Modify experiment parameters in `config.py` to customize your setup.
- Adjust the sample size for experiments in `utils.py` to fine-tune performance.
- sampler.py ï¼šTweak parameters for hierarchical Gaussian mixture sampling and clustering logic:
<sample_threshold> ï¼šThreshold for triggering clustering during sampling .
<n_clusters>  ï¼šNumber of clusters for sampling. If set to None, the value is automatically calculated as the square root of the total sample count (sqrt(N)).
<sample_num> ï¼šMaximum number of samples selected per cluster .
<topk_cluster> ï¼šTop-k high-priority clusters selected for sampling .
<lambda_inter> ï¼šMean regularization weight for inter-cluster constraints .
<beta_intra> ï¼šPenalty weight for the trace of intra-cluster covariance .
<w_balance> ï¼šDirectional penalty weight for intra-cluster covariance .
<max_iter> ï¼šMaximum number of iterations for the Expectation-Maximization (EM) algorithm .
<tol> ï¼šConvergence tolerance based on log-likelihood .
<reg_covar> ï¼šBase regularization term for covariance matrices .
---
## ğŸ“ Citation

If you find HGMF useful for your research, please cite our work:

```bibtex
@misc{xing2025hgmfhierarchicalgaussianmixture,
      title={HGMF: A Hierarchical Gaussian Mixture Framework for Scalable Tool Invocation within the Model Context Protocol}, 
      author={Wenpeng Xing and Zhipeng Chen and Changting Lin and Meng Han},
      year={2025},
      eprint={2508.07602},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2508.07602}, 
}
```

---

## ğŸ“œ License

HGMF is licensed under the [MIT License](LICENSE). Please review the license file for details.

---

## ğŸ‘ Acknowledgements

We thank the following projects and communities for their contributions and inspiration:
- [Ollama](https://ollama.ai): For providing an efficient LLM serving platform.
- [MCP-zero]: (https://github.com/xfey/MCP-Zero)For its open-source implementation of the Model Context Protocol (MCP) â€” which served as a key reference for designing our hierarchical tool invocation context framework.
---

## ğŸŒŸ About

HGMF is a pioneering framework for scalable tool invocation, designed to empower researchers and developers in building efficient AI-driven systems. We welcome contributions, feedback, and collaboration to advance this exciting field!

---

## ğŸ“¬ Contact

For questions, suggestions, or collaboration opportunities, please reach out to us:
- ğŸ“§ Email: [wpxing@zju.edu.cn, zhipengchen@jmu.edu.cn]
---

Â© 2025 GenTel Lab Team
